title: describing causation
---
hero_image:
---
pub_date: 2021-05-14
---
body:
## why we need causal inference
Whether you work as an academic physicist, a professional athelete, or an instagram influencer, an understanding of causation is essential to be effective in your work. Examples of questions which may be important to these people include: 
- *What experiment can I perform to test my new theory?*,
- *Which calories should I be consuming to minimize my recovery time?*, and
- *How can I write photo captions to maximize my number of likes on a post?*

all of which require a capacity to causally reason to answer. As humans[^1], an understanding of causation comes to us by second nature - presumably from the 1000s of years of evolution - with even children demonstrating a grasp of this fundamental property of the universe from a very young age. Perhaps it would be surprising to hear then that the mathematical language of Statistics lacks the vocabulary to describe causation. I was certainly taken aback. This is because the development of modern statistical theory was optimized to express associative relationships, $p(y|x)$, rather than causal ones. To make this notion more concrete, lets take the consider the association between the age of Miss America between the years 1999 and 2009, and the number of murders by steam, hot vapours, and hot objects in the USA in that same time span.

<div class="caption">
  <img src="./chart.png" class="shadow-img">
  <p>Source: <a href="https://tylervigen.com/spurious-correlations"> Tyler Vigen's spurious correlations.</a></p>
</div>

Computing the **<a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient"> Pearson correlation coefficient</a>**, $\rho$, between these two clearly unrelated variables yields a value of $\rho=0.870127$ or $\rho=87\%$[^2]. Does one now conclude that the organisers of the Miss America competition must crown younger and younger winners to prevent any more ghastly murders with hot objects? Or, given that the correlation coefficient has no opinion on what we model as $x$ or $y$, that more people who are murdered by hot objects results in a crowning of a relatively older Miss America? Of course not, but we can only say this given our *a priori* knowledge of these two variables. What if we were trying to model a complex biological system where much less is known about the variables of interest? It becomes near-impossible to discern who is listening to whom.

The field of causal inference attempts to bridge this gap left by Statistics through developing a concise analytical language capable of describing and interrogating causal relationships (relationships between the data describing a cause and an effect, for which the cause is an event that contributes to the production of another event, the effect). With this added string to our bow, our mathematical vocabulary dramatically expands ascending us past observational descriptions of data (Rung 1; What is?), and enables us to begin articulating interventional (Rung 2; What if?) and counterfactual (Rung 3; Why?) descriptions of data. This notion is illustrated below and is known as **<a href="https://causalai.net/r60.pdf"> Pearl's ladder of causation</a>**. As one would expect, descriptions of causal relationships are much richer in information than their associative counterparts, and hence serve as a superior guide for informed decision-making.
<div class="caption">
  <img src="./causation-ladder.jpg" class="shadow-img">
  <p>Source: <a href="https://causalai.net/r60.pdf"> Pearl's ladder of causation</a></p>
</div>

## directed acyclic graphs (DAGs)
Before constructing models capable of encapsulating causality, we must first become familiar with the notion of directed acyclic graphs, or DAGs. A DAG is a graph - in the computer science sense, not the statistical sense - comprised of nodes (variables) and edges for which the direction of an edge determines the relationship between the two nodes on either side. An example of a DAG is shown below (left) comprised of arbitrary variables $\\{A, B, C, D, E\\}$. For a graph like this to be classified as a DAG, it is essential no cycles are present within the graph's sturcture (clues in the name) where a cycle is classified as a path comprised of at least one edge that start and end with the same node. An example of a directed graph, but not a DAG, is presented below (right) with the graph's cycle highlighted in red.

<div class="row">
  <div class="column">
    <img src="./DAG-2.png" alt="DAG" style="width:100%">
    <p>Figure 1: Directed acyclic graph.</p>
  </div>
  <div class="column">
    <img src="./DCG-2.png" alt="DCG" style="width:100%">
    <p>Figure 2: directed cyclic graph.</p>
  </div>
</div>

## structural causal models (SCMs)
Developed by **<a href="http://bayes.cs.ucla.edu/BOOK-2K/neuberg-review.pdf"> Pearl (2000)</a>**, a structural causal model supersedes a causal DAG and is comprised of three main components:

1. A **set of variables** describing the state of your system of interest, and how they relate to the dataset at hand. These variables are: (1) **<span style="color:#01024e"> explanatory variables</span>**, (2) **<span style="color:#8b4367"> outcome variables</span>**, and (3) **<span style="color:#ff6464"> unobserved variables</span>**. These distinctions become extremely useful in causal inference problems since in practice we are often interested in the change of the outcome variable(s) due to an interventional change of an explanatory variable(s).

2. **Causal relationships** which describe the causal effect variables have on one another. Such relationships are expressed using the assignment operator '$\leftarrow$' and function notation '$f$' with a subscript labelling the variable which they effect.

3. A **probability distribution** defined over unobserved variables in the model, describing the likelihood that each variable takes a particular value.

For example, **<a href="https://arxiv.org/pdf/2005.07180.pdf"> this paper (von KÃ¼gelgen et al., 2021)</a>** choses to model <span style="color:#01024e"> country</span> $\color{#01024e}C$ and <span style="color:#01024e"> age</span> $\color{#01024e}A$ as explanatory variables for the <span style="color:#8b4367"> covid-19 mortality rate</span> $\color{#8b4367}M$ outcome variable. Whilst no unobserved variables are explicitly considered, the authors do mention that "*it is safe to assume that the virus is ultimately agnostic to the notion of different countries and that the influence of country on mortality $\color{#01024e}C$ $\rightarrow$ $\color{#8b4367}M$ is not actually a direct one, but instead mediated by additional variables $\color{#4B0082}U_i$. Candidates for such unobserved variables $\color{#8b4367} U_i$ include, e.g. <span style="color:#4B0082"> non-pharmaceutical interventions</span>*." hence acknowledging their existence. Let us explicitly use $U$ to denote this unobserved observable enabling us to propose the following structural equations for this system:
$$M \leftarrow f_M(U)$$  $$C \leftarrow f_C(M, U)$$

Combine these equations in conjunction with an arbitrary probability distribution defined over the unobserved variable $U$, and you are in possession of a fully specified SCM.
## SCMs $\cap$ DAGs
As you can probably tell, the intersectional area between SCMs and DAGs is extremely large and it turns out that the relationships between the observed variables in an SCMs adhere to the same set of restrictions defining DAGs. That is, all causal relationships between observational variables must be uni-directional such that they are prohibited from causally influencing themselves via a feedback loop (see the red arrows on the right of Fig. 1). Therefore, if one endows the edges of their DAG with a causal meaning, we create what is known as a **<a href="https://en.wikipedia.org/wiki/Causal_graph">causal graph</a>** providing a visual representation of their SCM. Succinctly put, **causal graphs are the DAG representations of structural causal models.**

<!-- TODO: MAP STRUCTURAL EQUATIONS TO CAUSAL MODELS WITH EXAMPLES -->
"Nothing is wrong with making assumptions; causal inference is impossible without making assumptions, and they are the strands that link statistics to science. It is the scientific quality of those assumptions, not their existence, that is critical." - Rubin, 1986.



[^1]: Maybe a robot will read this blog post one day.
[^2]: Karl Pearson actually believed that causation was actually just a special case of association, so when cracks such as this began to present themselves in his hypothesis, he coined these relationships as "spurious correlations" rather than acknowledging the need for a description of causality - a English gentry way of saying "these examples don't count".
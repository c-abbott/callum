title: Causal Estimation
---
hero_image:
---
pub_date: 2021-05-18
---
body:

In this blog post, I will be detailing various estimation methods commonly untilised in the field of causal inference.

### <a name="causalworkflow"> The Causal Workflow</a>
The workflow of causal inference always begins with a question: 
+ *How effective is a new drug?*
+ *Did the new tax policy improve wealth inequality, or exacerbate it?*
+ *Which of these thumbnails generates the highest click-through-rate (CTR) on our new YouTube video?*

By nature, human beings ask these kinds of causal questions on a day-to-day basis, with even small children capable of grasping the concept of causation at a very early age. You may be surprised to hear then that to answer these questions rigorously, the classical framework of statistics is insufficient. For instance, if one thinks of statistics, and mathematics in general, analgous to how one thinks of language, then the vocabulary of statistics simply has no words to describe causation; only association. I won't be proving this bold claim here, but if you aren't satisfied, then I suggest scrolling around on **<a href="https://twitter.com/yudapearl">Judea Pearl's Twitter</a>** for more than 5 minutes; he's been shouting about this stuff since the late 80s.

Returning back to the topic at hand, the framework of causal inference builds on classical statistics to directly answer causal questions. First, we must succinctly convert our causal question into a *causal estimand*. Once this quanitity has been *identified*, converting it from a causal into a *statistical estimand*, then one can obtain a real-valued *estimate* of this quantity through the process of *estimation*. This workflow has been neatly illustrated by Brady Neal below. Obtaining this estimate is the overall goal of causal inference, since once it is in your possession, you now have a single number which quantifies the causal relationship of interest.
<div class="caption">
  <img src="./causal-flowchart.png" class="shadow-img">
  <p>Source: <a href="https://www.bradyneal.com/causal-inference-course"> Brady Neal's causal inference course.</a></p>
</div>

### Potential Outcomes and Treatment Effects
Before delving into concrete causal estimation techniques, we must first become familiar with the notion of potential outcomes. Imagine we are a leading public economists interested in increasing the quality of life for the citizens of our nation. One way of quantifying a citizen's quality of life would be to examine their median household income adjusted for the cost of living in their location[^1]. Our goal is to hence implement a new publicy policy (a interventional treatment, $T$) such that its causal effect increases the median household income in our nation (an outcome $Y$). Suppose we conjured up, as well as rolled out this magical policy throughout our nation, and we now want to assess whether we attained our intended goal. We can subsequently map this assessment into the causal question of *"Did the new public policy improve the quality of life for our citizens?"* returning us to the first stage of the [**Causal Workflow**](#causalworkflow).

As devout followers of the Causal Workflow, we proceed in our assessment by converting our causal question of interest into a causal estimand like so:

$$\text{Treatment/Causal Effect} = Y |{\text{do}(T=1)} - Y |{\text{do}(T=0)} \triangleq Y(1) - Y(0)$$
Where:
- $\triangleq$ denotes an equality by definition
- $\text{do}(T=t) \; \forall \; t = 0, 1$ denotes the intervention of treatment irrespective of any other factors
- $T$ denotes the treatment e.g. the new public policy
- $Y$ denotes the outcome e.g. the change in the median household income
- $Y(t)$ denotes the potential outcome given the treatment was assigned $t=1$, or not $t=0$

However, keen readers may notice a problem with our formulation in that we only ever have access to $Y(1)$ or $Y(0)$, but never both; this is known as the **<a href="https://chabefer.github.io/STCI/FPCI.html"> Fundamental Problem of Causal Inference</a>**. Succinctly put, either the policy was implemented and we observe $Y(1)$, or it wasn't and we observe $Y(0)$, you can't have both. 

In the context of our economists example, a blanket rollout of our new policy would make the causal effect impossible to compute since we would only have observed the factual quantity $Y(1)$, and not the counterfactual quantity, $Y(0)$ by definition. I should note here that people often like to reason about counterfactual quantities by considering an alternative, hypothetical universe in which the denoted event occured i.e. a universe in which the policy was not implemented. I think Ken Acquah illustrates this nicely in the figure depicted below where he considers the effect of attending grad school versus going directly into an industry job on his income. Given that we have no access to this hypothetical universe, how are we supposed to make progress from here?

<div class="caption">
  <img src="./counterfactuals.png" class="shadow-img">
  <p>Source: <a href="https://www.causalflows.com/potential-outcomes-model/"> Ken Acquah's causal flows blog.</a></p>
</div>

### RCTs and ATEs





[^1]: Ideally, we would also adjust for the inflation rate in our fictitious nation, but for brevity's sake, we leave this to one side in this example. Any reference to the median household income from here onwards assumes it has been adjusted for the cost of living and inflation.
